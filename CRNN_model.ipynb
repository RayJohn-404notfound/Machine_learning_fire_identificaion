{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNh+r8sMBjfmhB7G1ro5JhL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RayJohn-404notfound/Machine_learning_fire_identificaion/blob/main/CRNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4VEzUEJOAXa",
        "outputId": "7b7f31bc-2770-4487-b64b-f2931f6c521e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sox\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from sox) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from sox) (4.13.2)\n",
            "Building wheels for collected packages: sox\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40036 sha256=49e0eca719f416b09961dd1cc3db7e9fa8359605e11709b651e11a7a926b60d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/89/93/023fcdacaec4e5471e78b43992515e8500cc2505b307e2e6b7\n",
            "Successfully built sox\n",
            "Installing collected packages: sox\n",
            "Successfully installed sox-1.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install sox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZALDE5nmOJpn",
        "outputId": "cc395e73-b378-4d17-b6c0-a295eae99cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl17msUtOJV8",
        "outputId": "c81467a9-f3b7-4157-9708-2376ca92206c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U snntorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmN7UD84OJOw",
        "outputId": "809148d7-c896-4c81-ecaa-96a27ed1a9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: snntorch\n",
            "Successfully installed snntorch-0.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3XtL78KOJF7",
        "outputId": "a4d38007-8f59-4103-8105-c6de90ad89ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torch-optimizer) (2.6.0+cu124)\n",
            "Collecting pytorch-ranger>=0.1.1 (from torch-optimizer)\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl.metadata (509 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.5.0->torch-optimizer)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch-optimizer) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torch-optimizer) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torch-optimizer) (3.0.2)\n",
            "Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-ranger, torch-optimizer\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr8vpBjDOI5b",
        "outputId": "7d4f5b5e-b134-4e9c-f41b-4f14431b5454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvsgw2IrOduc",
        "outputId": "8ea41bcd-751a-45b4-d3c4-d5e4d8a10183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "import psutil\n",
        "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlShutdown\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "# ===================== 0. Configuration Class =====================\n",
        "\n",
        "def get_optimal_num_workers():\n",
        "    \"\"\"自动计算最优的worker数量\"\"\"\n",
        "    try:\n",
        "        import multiprocessing\n",
        "        cpu_count = multiprocessing.cpu_count()\n",
        "        # 在Colab/Jupyter环境中，通常建议使用较少的worker\n",
        "        # 避免创建过多进程导致性能下降\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            return min(2, cpu_count)\n",
        "        else:\n",
        "            return min(4, cpu_count)\n",
        "    except:\n",
        "        return 2  # 默认安全值\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CRNNConfig:\n",
        "    \"\"\"CRNN模型和训练配置\"\"\"\n",
        "\n",
        "    # 数据配置\n",
        "    data_root: str = \"/content/drive/MyDrive/data\"\n",
        "    train_ratio: float = 0.8\n",
        "    sample_rate: int = 16000\n",
        "    n_fft: int = 1024\n",
        "    hop_length: int = 320\n",
        "    n_mels: int = 64\n",
        "\n",
        "    # 模型架构配置\n",
        "    num_classes: int = 2\n",
        "    cnn_channels: List[int] = None  # 将在__post_init__中设置\n",
        "    kernel_size: int = 3\n",
        "    padding: int = 1\n",
        "    pool_size: Tuple[int, int] = (2, 2)\n",
        "\n",
        "    # RNN配置\n",
        "    hidden_size: int = 128\n",
        "    rnn_layers: int = 2\n",
        "    bidirectional: bool = True\n",
        "    rnn_type: str = \"GRU\"  # \"GRU\" or \"LSTM\"\n",
        "\n",
        "    # Dropout配置\n",
        "    dropout_cnn: float = 0.35\n",
        "    dropout_rnn: float = 0.55\n",
        "\n",
        "    # 训练配置\n",
        "    batch_size: int = 64\n",
        "    learning_rate: float = 5e-5\n",
        "    weight_decay: float = 1e-5\n",
        "    max_epochs: int = 80\n",
        "    patience: int = 25\n",
        "    grad_clip_norm: float = 1.0\n",
        "\n",
        "    # 优化器和调度器配置\n",
        "    optimizer_type: str = \"Adam\"  # \"Adam\", \"AdamW\", \"SGD\"\n",
        "    scheduler_type: str = \"CosineAnnealing\"  # \"CosineAnnealing\", \"StepLR\", \"ReduceLROnPlateau\"\n",
        "    scheduler_T_max: int = 80\n",
        "    scheduler_step_size: int = 20\n",
        "    scheduler_gamma: float = 0.5\n",
        "    scheduler_patience: int = 10\n",
        "    scheduler_factor: float = 0.5\n",
        "\n",
        "    # 数据加载配置\n",
        "    num_workers: int = 0  # 将在__post_init__中自动设置\n",
        "    pin_memory: bool = True\n",
        "\n",
        "    # 设备和随机种子配置\n",
        "    device: str = \"auto\"  # \"auto\", \"cuda\", \"cpu\"\n",
        "    random_seed: int = 42\n",
        "\n",
        "    # 保存和输出配置\n",
        "    save_best_model: bool = True\n",
        "    model_save_path: str = \"best_model_crnn.pt\"\n",
        "    plot_results: bool = True\n",
        "    verbose: bool = True\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"初始化后处理\"\"\"\n",
        "        if self.cnn_channels is None:\n",
        "            self.cnn_channels = [16, 32]\n",
        "\n",
        "        # 自动设置设备\n",
        "        if self.device == \"auto\":\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # 自动设置最优worker数量\n",
        "        if self.num_workers == 0:\n",
        "            self.num_workers = get_optimal_num_workers()\n",
        "            if self.verbose:\n",
        "                print(f\"Auto-detected optimal num_workers: {self.num_workers}\")\n",
        "\n",
        "    def get_rnn_output_size(self) -> int:\n",
        "        \"\"\"计算RNN输出尺寸\"\"\"\n",
        "        multiplier = 2 if self.bidirectional else 1\n",
        "        return self.hidden_size * multiplier\n",
        "\n",
        "    def print_config(self):\n",
        "        \"\"\"打印配置信息\"\"\"\n",
        "        if not self.verbose:\n",
        "            return\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"CRNN Configuration Summary\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(f\"Random Seed: {self.random_seed}\")\n",
        "        print(f\"Data Root: {self.data_root}\")\n",
        "        print(f\"Train Ratio: {self.train_ratio}\")\n",
        "        print()\n",
        "        print(\"Model Architecture:\")\n",
        "        print(f\"  CNN Channels: {self.cnn_channels}\")\n",
        "        print(f\"  RNN Type: {self.rnn_type}\")\n",
        "        print(f\"  Hidden Size: {self.hidden_size}\")\n",
        "        print(f\"  RNN Layers: {self.rnn_layers}\")\n",
        "        print(f\"  Bidirectional: {self.bidirectional}\")\n",
        "        print(f\"  Dropout CNN: {self.dropout_cnn}\")\n",
        "        print(f\"  Dropout RNN: {self.dropout_rnn}\")\n",
        "        print()\n",
        "        print(\"Training Configuration:\")\n",
        "        print(f\"  Batch Size: {self.batch_size}\")\n",
        "        print(f\"  Learning Rate: {self.learning_rate}\")\n",
        "        print(f\"  Max Epochs: {self.max_epochs}\")\n",
        "        print(f\"  Patience: {self.patience}\")\n",
        "        print(f\"  Optimizer: {self.optimizer_type}\")\n",
        "        print(f\"  Scheduler: {self.scheduler_type}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# ===================== 1. Dataset and Preprocessing =====================\n",
        "\n",
        "class FireDataset(Dataset):\n",
        "    def __init__(self, file_list, labels, config: CRNNConfig):\n",
        "        self.file_list = file_list\n",
        "        self.labels = labels\n",
        "        self.config = config\n",
        "\n",
        "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=config.sample_rate,\n",
        "            n_fft=config.n_fft,\n",
        "            hop_length=config.hop_length,\n",
        "            n_mels=config.n_mels,\n",
        "            window_fn=torch.hann_window\n",
        "        )\n",
        "        self.amp_to_db = torchaudio.transforms.AmplitudeToDB(stype='power')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_list[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        waveform, sr = torchaudio.load(file_path)\n",
        "        if sr != self.config.sample_rate:\n",
        "            resampler = torchaudio.transforms.Resample(sr, self.config.sample_rate)\n",
        "            waveform = resampler(waveform)\n",
        "\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        mel_spec = self.mel_transform(waveform)\n",
        "        mel_spec_db = self.amp_to_db(mel_spec)\n",
        "\n",
        "        return mel_spec_db, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "def extract_group(file_path):\n",
        "    return os.path.basename(file_path).split(\"-\")[0]\n",
        "\n",
        "\n",
        "def load_data_secure(config: CRNNConfig):\n",
        "    fire_dir = os.path.join(config.data_root, \"fire\")\n",
        "    nofire_dir = os.path.join(config.data_root, \"nofire\")\n",
        "\n",
        "    fire_files = glob.glob(os.path.join(fire_dir, \"*.wav\"))\n",
        "    nofire_files = glob.glob(os.path.join(nofire_dir, \"*.wav\"))\n",
        "\n",
        "    if config.verbose:\n",
        "        print(f\"Found {len(fire_files)} fire files, {len(nofire_files)} nofire files\")\n",
        "\n",
        "    file_list = fire_files + nofire_files\n",
        "    labels = [1] * len(fire_files) + [0] * len(nofire_files)\n",
        "    groups = [extract_group(f) for f in file_list]\n",
        "\n",
        "    splitter = GroupShuffleSplit(n_splits=1, test_size=1 - config.train_ratio, random_state=config.random_seed)\n",
        "    train_idx, test_idx = next(splitter.split(file_list, labels, groups=groups))\n",
        "\n",
        "    train_files = [file_list[i] for i in train_idx]\n",
        "    train_labels = [labels[i] for i in train_idx]\n",
        "    test_files = [file_list[i] for i in test_idx]\n",
        "    test_labels = [labels[i] for i in test_idx]\n",
        "\n",
        "    train_dataset = FireDataset(train_files, train_labels, config)\n",
        "    test_dataset = FireDataset(test_files, test_labels, config)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "# ===================== 2. Improved CRNN Model Definition =====================\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, config: CRNNConfig, input_shape=(1, 64, 128)):\n",
        "        super(CRNN, self).__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # 构建CNN层\n",
        "        layers = []\n",
        "        in_channels = input_shape[0]\n",
        "\n",
        "        for out_channels in config.cnn_channels:\n",
        "            layers.extend([\n",
        "                nn.Conv2d(in_channels, out_channels,\n",
        "                         kernel_size=config.kernel_size,\n",
        "                         padding=config.padding),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(config.pool_size)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "        self.dropout_cnn = nn.Dropout(config.dropout_cnn)\n",
        "\n",
        "        # 动态计算RNN输入大小\n",
        "        self.rnn_input_size = self._calculate_rnn_input_size(input_shape)\n",
        "\n",
        "        # 构建RNN层\n",
        "        if config.rnn_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(\n",
        "                input_size=self.rnn_input_size,\n",
        "                hidden_size=config.hidden_size,\n",
        "                num_layers=config.rnn_layers,\n",
        "                batch_first=True,\n",
        "                bidirectional=config.bidirectional\n",
        "            )\n",
        "        elif config.rnn_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(\n",
        "                input_size=self.rnn_input_size,\n",
        "                hidden_size=config.hidden_size,\n",
        "                num_layers=config.rnn_layers,\n",
        "                batch_first=True,\n",
        "                bidirectional=config.bidirectional\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported RNN type: {config.rnn_type}\")\n",
        "\n",
        "        self.dropout_rnn = nn.Dropout(config.dropout_rnn)\n",
        "\n",
        "        # 注意力机制和分类层\n",
        "        rnn_output_size = config.get_rnn_output_size()\n",
        "        self.attn_layer = nn.Linear(rnn_output_size, 1)\n",
        "        self.fc = nn.Linear(rnn_output_size, config.num_classes)\n",
        "\n",
        "    def _calculate_rnn_input_size(self, input_shape):\n",
        "        \"\"\"动态计算RNN输入大小\"\"\"\n",
        "        dummy_input = torch.zeros(1, *input_shape)\n",
        "        with torch.no_grad():\n",
        "            out = self.conv(dummy_input)\n",
        "            out = self.dropout_cnn(out)\n",
        "            _, channels, height, _ = out.shape\n",
        "        return channels * height\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN特征提取\n",
        "        x = self.conv(x)\n",
        "        x = self.dropout_cnn(x)\n",
        "\n",
        "        # 重塑为RNN输入格式\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = x.contiguous().view(x.size(0), x.size(1), -1)\n",
        "\n",
        "        # RNN处理\n",
        "        if self.config.rnn_type == \"LSTM\":\n",
        "            rnn_out, _ = self.rnn(x)\n",
        "        else:  # GRU\n",
        "            rnn_out, _ = self.rnn(x)\n",
        "\n",
        "        rnn_out = self.dropout_rnn(rnn_out)\n",
        "\n",
        "        # 注意力机制\n",
        "        attn_weights = torch.softmax(self.attn_layer(rnn_out), dim=1)\n",
        "        context = torch.sum(attn_weights * rnn_out, dim=1)\n",
        "\n",
        "        return self.fc(context)\n",
        "\n",
        "    def get_attention_weights(self, x):\n",
        "        \"\"\"获取注意力权重用于可视化\"\"\"\n",
        "        x = self.conv(x)\n",
        "        x = self.dropout_cnn(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = x.contiguous().view(x.size(0), x.size(1), -1)\n",
        "\n",
        "        if self.config.rnn_type == \"LSTM\":\n",
        "            rnn_out, _ = self.rnn(x)\n",
        "        else:\n",
        "            rnn_out, _ = self.rnn(x)\n",
        "\n",
        "        rnn_out = self.dropout_rnn(rnn_out)\n",
        "        attn_weights = torch.softmax(self.attn_layer(rnn_out), dim=1)\n",
        "\n",
        "        return attn_weights.squeeze(-1)  # [batch, time_steps]\n",
        "\n",
        "\n",
        "# ===================== 3. Improved Training & Testing =====================\n",
        "\n",
        "def create_optimizer(model, config: CRNNConfig):\n",
        "    \"\"\"根据配置创建优化器\"\"\"\n",
        "    if config.optimizer_type == \"Adam\":\n",
        "        return optim.Adam(model.parameters(),\n",
        "                         lr=config.learning_rate,\n",
        "                         weight_decay=config.weight_decay)\n",
        "    elif config.optimizer_type == \"AdamW\":\n",
        "        return optim.AdamW(model.parameters(),\n",
        "                          lr=config.learning_rate,\n",
        "                          weight_decay=config.weight_decay)\n",
        "    elif config.optimizer_type == \"SGD\":\n",
        "        return optim.SGD(model.parameters(),\n",
        "                        lr=config.learning_rate,\n",
        "                        weight_decay=config.weight_decay,\n",
        "                        momentum=0.9)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported optimizer: {config.optimizer_type}\")\n",
        "\n",
        "\n",
        "def create_scheduler(optimizer, config: CRNNConfig):\n",
        "    \"\"\"根据配置创建学习率调度器\"\"\"\n",
        "    if config.scheduler_type == \"CosineAnnealing\":\n",
        "        return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.scheduler_T_max)\n",
        "    elif config.scheduler_type == \"StepLR\":\n",
        "        return optim.lr_scheduler.StepLR(optimizer,\n",
        "                                       step_size=config.scheduler_step_size,\n",
        "                                       gamma=config.scheduler_gamma)\n",
        "    elif config.scheduler_type == \"ReduceLROnPlateau\":\n",
        "        return optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                   mode='max',\n",
        "                                                   patience=config.scheduler_patience,\n",
        "                                                   factor=config.scheduler_factor)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported scheduler: {config.scheduler_type}\")\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, optimizer, loss_fn, config: CRNNConfig):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False) if config.verbose else train_loader\n",
        "\n",
        "    for data, target in progress_bar:\n",
        "        data, target = data.to(config.device), target.to(config.device)\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.grad_clip_norm)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def test_model(model, test_loader, config: CRNNConfig):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False) if config.verbose else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in progress_bar:\n",
        "            data, target = data.to(config.device), target.to(config.device)\n",
        "            output = model(data)\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "# ===================== 4. Memory Monitor =====================\n",
        "\n",
        "def print_memory_usage(config: CRNNConfig):\n",
        "    if not config.verbose:\n",
        "        return\n",
        "\n",
        "    print(\"\\n=== Resource Usage Summary ===\")\n",
        "    mem = psutil.virtual_memory()\n",
        "    print(f\"System RAM Used: {mem.percent:.2f}% ({mem.used / 1e9:.2f} GB / {mem.total / 1e9:.2f} GB)\")\n",
        "\n",
        "    if torch.cuda.is_available() and config.device == \"cuda\":\n",
        "        try:\n",
        "            nvmlInit()\n",
        "            handle = nvmlDeviceGetHandleByIndex(0)\n",
        "            info = nvmlDeviceGetMemoryInfo(handle)\n",
        "            used_gb = info.used / 1e9\n",
        "            total_gb = info.total / 1e9\n",
        "            used_percent = (info.used / info.total) * 100\n",
        "            print(f\"GPU RAM Used: {used_percent:.2f}% ({used_gb:.2f} GB / {total_gb:.2f} GB)\")\n",
        "            nvmlShutdown()\n",
        "        except:\n",
        "            print(\"GPU memory info unavailable\")\n",
        "    else:\n",
        "        print(\"GPU not available or not using CUDA.\")\n",
        "\n",
        "\n",
        "# ===================== 5. Main Function =====================\n",
        "\n",
        "def main(config: CRNNConfig = None):\n",
        "    if config is None:\n",
        "        config = CRNNConfig()\n",
        "\n",
        "    # 设置随机种子\n",
        "    torch.manual_seed(config.random_seed)\n",
        "    random.seed(config.random_seed)\n",
        "    np.random.seed(config.random_seed)\n",
        "\n",
        "    # 打印配置\n",
        "    config.print_config()\n",
        "\n",
        "    # 加载数据\n",
        "    train_dataset, test_dataset = load_data_secure(config)\n",
        "\n",
        "    # 创建数据加载器\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        num_workers=12,\n",
        "        pin_memory=config.pin_memory\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        num_workers=12,\n",
        "        pin_memory=config.pin_memory\n",
        "    )\n",
        "\n",
        "    # 获取输入形状\n",
        "    sample_input, _ = train_dataset[0]\n",
        "    input_shape = tuple(sample_input.shape)\n",
        "\n",
        "    # 创建模型\n",
        "    model = CRNN(config, input_shape).to(config.device)\n",
        "\n",
        "    # 打印模型信息\n",
        "    if config.verbose:\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        print(f\"\\nModel Parameters: {total_params:,} total, {trainable_params:,} trainable\")\n",
        "\n",
        "    # 创建优化器和调度器\n",
        "    optimizer = create_optimizer(model, config)\n",
        "    scheduler = create_scheduler(optimizer, config)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 训练循环\n",
        "    best_acc = 0\n",
        "    patience_counter = 0\n",
        "    train_loss_list, train_acc_list, test_acc_list = [], [], []\n",
        "\n",
        "    for epoch in range(1, config.max_epochs + 1):\n",
        "        if config.verbose:\n",
        "            print(f\"\\nEpoch {epoch}/{config.max_epochs}\")\n",
        "\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # 训练\n",
        "        train_loss = train_model(model, train_loader, optimizer, loss_fn, config)\n",
        "\n",
        "        # 评估\n",
        "        train_acc = test_model(model, train_loader, config)\n",
        "        test_acc = test_model(model, test_loader, config)\n",
        "\n",
        "        # 记录指标\n",
        "        train_loss_list.append(train_loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "\n",
        "        # 更新学习率\n",
        "        if config.scheduler_type == \"ReduceLROnPlateau\":\n",
        "            scheduler.step(test_acc)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        # 打印结果\n",
        "        if config.verbose:\n",
        "            epoch_time = time.time() - epoch_start\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(f\"Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "            print(f\"LR: {current_lr:.2e}, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "        # 早停和保存最佳模型\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            if config.save_best_model:\n",
        "                torch.save(model.state_dict(), config.model_save_path)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config.patience:\n",
        "                if config.verbose:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    if config.verbose:\n",
        "        print(f\"\\nBest Test Accuracy: {best_acc:.4f}\")\n",
        "\n",
        "    # 打印资源使用\n",
        "    print_memory_usage(config)\n",
        "\n",
        "    # 绘制结果\n",
        "    if config.plot_results:\n",
        "        plot_results(train_loss_list, train_acc_list, test_acc_list, test_loader, model, config)\n",
        "\n",
        "    return model, best_acc, (train_loss_list, train_acc_list, test_acc_list)\n",
        "\n",
        "\n",
        "# ===================== 6. Plot Results (保持原有函数，但添加config参数) =====================\n",
        "\n",
        "def plot_results(train_loss_list, train_acc_list, test_acc_list, test_loader, model, config: CRNNConfig):\n",
        "    # 原有的绘图代码保持不变，但使用config.device\n",
        "    epochs = range(1, len(train_acc_list) + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, train_acc_list, label='Train Accuracy', color='royalblue', marker='o')\n",
        "    plt.plot(epochs, test_acc_list, label='Test Accuracy', color='darkorange', marker='o')\n",
        "    plt.title(\"Accuracy vs. Epoch\", fontsize=14)\n",
        "    plt.xlabel(\"Epoch\", fontsize=12)\n",
        "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"train_vs_test_accuracy.png\")\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(range(1, len(train_loss_list)+1), train_loss_list, label=\"Training Loss\", color='red', marker='s')\n",
        "    plt.title(\"Training Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlim(1, len(train_loss_list))\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_loss.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # 混淆矩阵和ROC曲线代码保持不变，使用config.device\n",
        "    all_preds, all_targets = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(config.device), target.to(config.device)\n",
        "            pred = torch.argmax(model(data), dim=1)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[\"nofire\", \"fire\"], yticklabels=[\"nofire\", \"fire\"])\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"confusion_matrix_crnn.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # ROC和PR曲线\n",
        "    model.eval()\n",
        "    y_true, y_score = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(config.device), y.to(config.device)\n",
        "            logits = model(x)\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_score.extend(probs.cpu().numpy())\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
        "    ap = average_precision_score(y_true, y_score)\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr, tpr, label=f\"ROC (AUC = {roc_auc:.3f})\", color=\"royalblue\")\n",
        "    plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
        "\n",
        "    ax2 = plt.gca().twinx()\n",
        "    ax2.plot(recall, precision, color=\"tomato\", label=f\"PR (AP = {ap:.3f})\")\n",
        "\n",
        "    plt.xlabel(\"False-Positive Rate\")\n",
        "    plt.ylabel(\"True-Positive Rate\")\n",
        "    ax2.set_ylabel(\"Precision\")\n",
        "    plt.title(\"ROC and Precision-Recall Curves\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    ax2.legend(loc=\"upper right\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"roc_pr_curves.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ===================== 7. 使用示例 =====================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 使用默认配置\n",
        "    main()\n",
        "\n",
        "    # 或者自定义配置\n",
        "    # custom_config = CRNNConfig(\n",
        "    #     learning_rate=1e-4,\n",
        "    #     batch_size=32,\n",
        "    #     hidden_size=256,\n",
        "    #     max_epochs=100,\n",
        "    #     rnn_type=\"LSTM\"\n",
        "    # )\n",
        "    # main(custom_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8B88OV_Oeew",
        "outputId": "d025cff3-9212-4202-9e65-f291bd9168ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-detected optimal num_workers: 2\n",
            "============================================================\n",
            "CRNN Configuration Summary\n",
            "============================================================\n",
            "Device: cuda\n",
            "Random Seed: 42\n",
            "Data Root: /content/drive/MyDrive/data\n",
            "Train Ratio: 0.8\n",
            "\n",
            "Model Architecture:\n",
            "  CNN Channels: [16, 32]\n",
            "  RNN Type: GRU\n",
            "  Hidden Size: 128\n",
            "  RNN Layers: 2\n",
            "  Bidirectional: True\n",
            "  Dropout CNN: 0.35\n",
            "  Dropout RNN: 0.55\n",
            "\n",
            "Training Configuration:\n",
            "  Batch Size: 64\n",
            "  Learning Rate: 5e-05\n",
            "  Max Epochs: 80\n",
            "  Patience: 25\n",
            "  Optimizer: Adam\n",
            "  Scheduler: CosineAnnealing\n",
            "============================================================\n",
            "Found 1697 fire files, 1562 nofire files\n",
            "\n",
            "Model Parameters: 795,171 total, 795,171 trainable\n",
            "\n",
            "Epoch 1/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5721, Train Acc: 0.8340, Test Acc: 0.8267\n",
            "LR: 5.00e-05, Time: 106.92s\n",
            "\n",
            "Epoch 2/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3958, Train Acc: 0.8562, Test Acc: 0.8528\n",
            "LR: 4.99e-05, Time: 13.80s\n",
            "\n",
            "Epoch 3/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2982, Train Acc: 0.9066, Test Acc: 0.9095\n",
            "LR: 4.98e-05, Time: 13.73s\n",
            "\n",
            "Epoch 4/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2341, Train Acc: 0.9305, Test Acc: 0.9371\n",
            "LR: 4.97e-05, Time: 13.82s\n",
            "\n",
            "Epoch 5/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1971, Train Acc: 0.9379, Test Acc: 0.9433\n",
            "LR: 4.95e-05, Time: 13.69s\n",
            "\n",
            "Epoch 6/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1743, Train Acc: 0.9488, Test Acc: 0.9448\n",
            "LR: 4.93e-05, Time: 13.63s\n",
            "\n",
            "Epoch 7/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1562, Train Acc: 0.9535, Test Acc: 0.9525\n",
            "LR: 4.91e-05, Time: 13.67s\n",
            "\n",
            "Epoch 8/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1446, Train Acc: 0.9527, Test Acc: 0.9617\n",
            "LR: 4.88e-05, Time: 13.76s\n",
            "\n",
            "Epoch 9/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1379, Train Acc: 0.9551, Test Acc: 0.9571\n",
            "LR: 4.85e-05, Time: 13.86s\n",
            "\n",
            "Epoch 10/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1302, Train Acc: 0.9590, Test Acc: 0.9617\n",
            "LR: 4.81e-05, Time: 13.66s\n",
            "\n",
            "Epoch 11/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1232, Train Acc: 0.9559, Test Acc: 0.9632\n",
            "LR: 4.77e-05, Time: 13.88s\n",
            "\n",
            "Epoch 12/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1151, Train Acc: 0.9574, Test Acc: 0.9647\n",
            "LR: 4.73e-05, Time: 13.65s\n",
            "\n",
            "Epoch 13/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1142, Train Acc: 0.9602, Test Acc: 0.9709\n",
            "LR: 4.68e-05, Time: 13.59s\n",
            "\n",
            "Epoch 14/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1072, Train Acc: 0.9602, Test Acc: 0.9632\n",
            "LR: 4.63e-05, Time: 13.71s\n",
            "\n",
            "Epoch 15/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1063, Train Acc: 0.9621, Test Acc: 0.9678\n",
            "LR: 4.58e-05, Time: 13.67s\n",
            "\n",
            "Epoch 16/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1052, Train Acc: 0.9586, Test Acc: 0.9678\n",
            "LR: 4.52e-05, Time: 13.75s\n",
            "\n",
            "Epoch 17/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1010, Train Acc: 0.9625, Test Acc: 0.9647\n",
            "LR: 4.46e-05, Time: 13.76s\n",
            "\n",
            "Epoch 18/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1007, Train Acc: 0.9668, Test Acc: 0.9678\n",
            "LR: 4.40e-05, Time: 13.68s\n",
            "\n",
            "Epoch 19/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0921, Train Acc: 0.9664, Test Acc: 0.9663\n",
            "LR: 4.34e-05, Time: 13.87s\n",
            "\n",
            "Epoch 20/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0913, Train Acc: 0.9680, Test Acc: 0.9678\n",
            "LR: 4.27e-05, Time: 13.96s\n",
            "\n",
            "Epoch 21/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0881, Train Acc: 0.9664, Test Acc: 0.9647\n",
            "LR: 4.20e-05, Time: 13.78s\n",
            "\n",
            "Epoch 22/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0911, Train Acc: 0.9668, Test Acc: 0.9663\n",
            "LR: 4.12e-05, Time: 13.77s\n",
            "\n",
            "Epoch 23/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0896, Train Acc: 0.9656, Test Acc: 0.9647\n",
            "LR: 4.05e-05, Time: 13.66s\n",
            "\n",
            "Epoch 24/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0850, Train Acc: 0.9668, Test Acc: 0.9647\n",
            "LR: 3.97e-05, Time: 13.78s\n",
            "\n",
            "Epoch 25/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0827, Train Acc: 0.9688, Test Acc: 0.9678\n",
            "LR: 3.89e-05, Time: 13.76s\n",
            "\n",
            "Epoch 26/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0805, Train Acc: 0.9695, Test Acc: 0.9678\n",
            "LR: 3.81e-05, Time: 13.89s\n",
            "\n",
            "Epoch 27/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0828, Train Acc: 0.9656, Test Acc: 0.9678\n",
            "LR: 3.72e-05, Time: 13.72s\n",
            "\n",
            "Epoch 28/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0861, Train Acc: 0.9691, Test Acc: 0.9678\n",
            "LR: 3.63e-05, Time: 13.80s\n",
            "\n",
            "Epoch 29/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0852, Train Acc: 0.9695, Test Acc: 0.9663\n",
            "LR: 3.55e-05, Time: 13.72s\n",
            "\n",
            "Epoch 30/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0776, Train Acc: 0.9695, Test Acc: 0.9663\n",
            "LR: 3.46e-05, Time: 13.70s\n",
            "\n",
            "Epoch 31/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0762, Train Acc: 0.9613, Test Acc: 0.9693\n",
            "LR: 3.37e-05, Time: 13.74s\n",
            "\n",
            "Epoch 32/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0836, Train Acc: 0.9695, Test Acc: 0.9663\n",
            "LR: 3.27e-05, Time: 13.80s\n",
            "\n",
            "Epoch 33/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0783, Train Acc: 0.9668, Test Acc: 0.9693\n",
            "LR: 3.18e-05, Time: 13.63s\n",
            "\n",
            "Epoch 34/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0691, Train Acc: 0.9703, Test Acc: 0.9693\n",
            "LR: 3.08e-05, Time: 13.61s\n",
            "\n",
            "Epoch 35/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0734, Train Acc: 0.9691, Test Acc: 0.9663\n",
            "LR: 2.99e-05, Time: 13.68s\n",
            "\n",
            "Epoch 36/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0761, Train Acc: 0.9699, Test Acc: 0.9678\n",
            "LR: 2.89e-05, Time: 13.59s\n",
            "\n",
            "Epoch 37/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0725, Train Acc: 0.9691, Test Acc: 0.9709\n",
            "LR: 2.79e-05, Time: 13.76s\n",
            "\n",
            "Epoch 38/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0701, Train Acc: 0.9656, Test Acc: 0.9693\n",
            "LR: 2.70e-05, Time: 13.99s\n",
            "Early stopping triggered.\n",
            "\n",
            "Best Test Accuracy: 0.9709\n",
            "\n",
            "=== Resource Usage Summary ===\n",
            "System RAM Used: 4.00% (2.61 GB / 89.63 GB)\n",
            "GPU RAM Used: 3.94% (1.69 GB / 42.95 GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lE5XF8XkOeWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}